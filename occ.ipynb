{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nildodnjunior/mestrado_comp_ifes_dissertacao/blob/master/occ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4B0GOd0b0ez",
        "outputId": "0ac5518b-a37f-4c12-a47e-257380fcbed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "Due to legal constraints, paper abstracts in SYNERGY cannot be published in\n",
            "plaintext. Abstracts are instead stored as an inverted index. Inverted\n",
            "indexes store information about each word in a body of text, including\n",
            "the number of occurrences and the position of each occurrence. Read\n",
            "more:\n",
            "- https://learn.microsoft.com/en-us/academic-services/graph/resources-faq\n",
            "- https://docs.openalex.org/api-entities/works/work-object\n",
            "\n",
            "For machine learning purposes, it can be helpful to convert the inverted\n",
            "abstract back into plaintext locally. Keep in mind that paper abstracts\n",
            "in SYNERGY cannot be published as plaintext again. Therefore you can refer\n",
            "to the version of the SYNERGY dataset.\n",
            "\n",
            "Would you like to convert the inverted abstract to plaintext? ([Y]es,[N]o):\n",
            "y\n",
            "Downloading version 1.0 of the SYNERGY dataset...\n",
            "Building dataset\n",
            "100% 26/26 [01:09<00:00,  2.68s/it]\n"
          ]
        }
      ],
      "source": [
        "!pip install synergy-dataset -q\n",
        "!pip install sentence-transformers -q\n",
        "!pip install transformers -q\n",
        "!python -m synergy_dataset get"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aZqhrcODbxxt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "\n",
        "from synergy_dataset import Dataset, iter_datasets\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ONFPEDPcdmHZ"
      },
      "outputs": [],
      "source": [
        "def cria_dataset(dataset):\n",
        "    ds = Dataset(dataset)\n",
        "    ds = ds.to_dict(variables=['title', 'abstract'])\n",
        "    ds = pd.DataFrame.from_dict(ds, orient='index')\n",
        "    ds = ds.fillna(' ')\n",
        "    title = ds['title']\n",
        "    abstract = ds['abstract']\n",
        "    X = np.array([x[0] + ' ' + x[1] for x in zip(title, abstract)])\n",
        "    y = np.array(ds['label_included'])\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRotCc27_sYv",
        "outputId": "c5e8aaa5-177b-4d52-b808-810c6c1840aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gsjQ82GGrjak"
      },
      "outputs": [],
      "source": [
        "occ_classifiers = ['OneClassSVM',\n",
        "              'Isolation Forest',\n",
        "              'Local Outlier Factor']\n",
        "\n",
        "model_checkpoints = ['sentence-transformers/all-MiniLM-L6-v2',\n",
        "                     'all-distilroberta-v1',\n",
        "                     'sentence-transformers/allenai-specter']\n",
        "\n",
        "datasets = ['Nelson_2002', 'Muthu_2021', 'Hall_2012', 'Wassenaar_2017']\n",
        "#Wassenaar_2017 e Hall_2012 foram incluídos por serem desbalanceados (1.4% e 1.2%),\n",
        "#para verificar se os classificadores OCC se saem melhor em datasets desse tipo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Acpy_szr-hh",
        "outputId": "e5b5b4fe-7537-483c-8214-db1dcb01fe49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "OneClassSVM\n",
            "Nelson_2002\n",
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.79      1.00      0.88       286\n",
            "           1       0.00      0.00      0.00        75\n",
            "\n",
            "    accuracy                           0.79       361\n",
            "   macro avg       0.40      0.50      0.44       361\n",
            "weighted avg       0.63      0.79      0.70       361\n",
            "\n",
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.82      0.94      0.88       286\n",
            "           1       0.41      0.17      0.24        70\n",
            "\n",
            "    accuracy                           0.79       356\n",
            "   macro avg       0.62      0.56      0.56       356\n",
            "weighted avg       0.74      0.79      0.75       356\n",
            "\n",
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.84      0.95      0.89       286\n",
            "           1       0.50      0.22      0.30        65\n",
            "\n",
            "    accuracy                           0.81       351\n",
            "   macro avg       0.67      0.58      0.60       351\n",
            "weighted avg       0.78      0.81      0.78       351\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.85      0.90      0.87       286\n",
            "           1       0.33      0.23      0.27        60\n",
            "\n",
            "    accuracy                           0.78       346\n",
            "   macro avg       0.59      0.57      0.57       346\n",
            "weighted avg       0.76      0.78      0.77       346\n",
            "\n",
            "Muthu_2021\n",
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.88      1.00      0.94      2383\n",
            "           1       0.00      0.00      0.00       331\n",
            "\n",
            "    accuracy                           0.88      2714\n",
            "   macro avg       0.44      0.50      0.47      2714\n",
            "weighted avg       0.77      0.88      0.82      2714\n",
            "\n",
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.89      0.97      0.93      2383\n",
            "           1       0.33      0.10      0.15       326\n",
            "\n",
            "    accuracy                           0.87      2709\n",
            "   macro avg       0.61      0.53      0.54      2709\n",
            "weighted avg       0.82      0.87      0.83      2709\n",
            "\n",
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.90      0.98      0.93      2383\n",
            "           1       0.47      0.15      0.23       321\n",
            "\n",
            "    accuracy                           0.88      2704\n",
            "   macro avg       0.68      0.56      0.58      2704\n",
            "weighted avg       0.84      0.88      0.85      2704\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.91      0.91      0.91      2383\n",
            "           1       0.31      0.31      0.31       316\n",
            "\n",
            "    accuracy                           0.84      2699\n",
            "   macro avg       0.61      0.61      0.61      2699\n",
            "weighted avg       0.84      0.84      0.84      2699\n",
            "\n",
            "Hall_2012\n",
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      1.00      0.99      8689\n",
            "           1       0.00      0.00      0.00        99\n",
            "\n",
            "    accuracy                           0.99      8788\n",
            "   macro avg       0.49      0.50      0.50      8788\n",
            "weighted avg       0.98      0.99      0.98      8788\n",
            "\n",
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      1.00      0.99      8689\n",
            "           1       0.83      0.05      0.10        94\n",
            "\n",
            "    accuracy                           0.99      8783\n",
            "   macro avg       0.91      0.53      0.55      8783\n",
            "weighted avg       0.99      0.99      0.99      8783\n",
            "\n",
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      1.00      1.00      8689\n",
            "           1       0.63      0.29      0.40        89\n",
            "\n",
            "    accuracy                           0.99      8778\n",
            "   macro avg       0.81      0.65      0.70      8778\n",
            "weighted avg       0.99      0.99      0.99      8778\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      1.00      1.00      8689\n",
            "           1       0.61      0.26      0.37        84\n",
            "\n",
            "    accuracy                           0.99      8773\n",
            "   macro avg       0.80      0.63      0.68      8773\n",
            "weighted avg       0.99      0.99      0.99      8773\n",
            "\n",
            "Wassenaar_2017\n",
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      1.00      0.99      7557\n",
            "           1       1.00      0.02      0.04       106\n",
            "\n",
            "    accuracy                           0.99      7663\n",
            "   macro avg       0.99      0.51      0.52      7663\n",
            "weighted avg       0.99      0.99      0.98      7663\n",
            "\n",
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      1.00      0.99      7557\n",
            "           1       0.78      0.07      0.13       101\n",
            "\n",
            "    accuracy                           0.99      7658\n",
            "   macro avg       0.88      0.53      0.56      7658\n",
            "weighted avg       0.98      0.99      0.98      7658\n",
            "\n",
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      0.99      0.99      7557\n",
            "           1       0.28      0.20      0.23        96\n",
            "\n",
            "    accuracy                           0.98      7653\n",
            "   macro avg       0.63      0.60      0.61      7653\n",
            "weighted avg       0.98      0.98      0.98      7653\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      0.98      0.98      7557\n",
            "           1       0.16      0.38      0.23        91\n",
            "\n",
            "    accuracy                           0.97      7648\n",
            "   macro avg       0.58      0.68      0.61      7648\n",
            "weighted avg       0.98      0.97      0.98      7648\n",
            "\n",
            "\n",
            "\n",
            "Isolation Forest\n",
            "Nelson_2002\n",
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.81      0.65      0.72       286\n",
            "           1       0.24      0.41      0.30        75\n",
            "\n",
            "    accuracy                           0.60       361\n",
            "   macro avg       0.52      0.53      0.51       361\n",
            "weighted avg       0.69      0.60      0.63       361\n",
            "\n",
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.91      0.60      0.72       286\n",
            "           1       0.32      0.76      0.45        70\n",
            "\n",
            "    accuracy                           0.63       356\n",
            "   macro avg       0.61      0.68      0.58       356\n",
            "weighted avg       0.79      0.63      0.67       356\n",
            "\n",
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.92      0.51      0.66       286\n",
            "           1       0.27      0.80      0.41        65\n",
            "\n",
            "    accuracy                           0.57       351\n",
            "   macro avg       0.60      0.66      0.53       351\n",
            "weighted avg       0.80      0.57      0.61       351\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.93      0.64      0.76       286\n",
            "           1       0.31      0.77      0.44        60\n",
            "\n",
            "    accuracy                           0.66       346\n",
            "   macro avg       0.62      0.71      0.60       346\n",
            "weighted avg       0.82      0.66      0.71       346\n",
            "\n",
            "Muthu_2021\n",
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.93      0.33      0.48      2383\n",
            "           1       0.15      0.82      0.25       331\n",
            "\n",
            "    accuracy                           0.39      2714\n",
            "   macro avg       0.54      0.58      0.37      2714\n",
            "weighted avg       0.83      0.39      0.45      2714\n",
            "\n",
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.94      0.40      0.56      2383\n",
            "           1       0.15      0.80      0.26       326\n",
            "\n",
            "    accuracy                           0.45      2709\n",
            "   macro avg       0.54      0.60      0.41      2709\n",
            "weighted avg       0.84      0.45      0.52      2709\n",
            "\n",
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.31      0.46      2383\n",
            "           1       0.15      0.92      0.26       321\n",
            "\n",
            "    accuracy                           0.38      2704\n",
            "   macro avg       0.56      0.61      0.36      2704\n",
            "weighted avg       0.87      0.38      0.44      2704\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.97      0.24      0.39      2383\n",
            "           1       0.14      0.95      0.25       316\n",
            "\n",
            "    accuracy                           0.32      2699\n",
            "   macro avg       0.56      0.60      0.32      2699\n",
            "weighted avg       0.88      0.32      0.37      2699\n",
            "\n",
            "Hall_2012\n",
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.93      0.96      8689\n",
            "           1       0.11      0.79      0.19        99\n",
            "\n",
            "    accuracy                           0.93      8788\n",
            "   macro avg       0.55      0.86      0.58      8788\n",
            "weighted avg       0.99      0.93      0.95      8788\n",
            "\n",
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      0.99      0.99      8689\n",
            "           1       0.28      0.53      0.36        94\n",
            "\n",
            "    accuracy                           0.98      8783\n",
            "   macro avg       0.64      0.76      0.68      8783\n",
            "weighted avg       0.99      0.98      0.98      8783\n",
            "\n",
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.96      0.98      8689\n",
            "           1       0.18      0.81      0.29        89\n",
            "\n",
            "    accuracy                           0.96      8778\n",
            "   macro avg       0.59      0.89      0.64      8778\n",
            "weighted avg       0.99      0.96      0.97      8778\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.98      0.99      8689\n",
            "           1       0.28      0.70      0.40        84\n",
            "\n",
            "    accuracy                           0.98      8773\n",
            "   macro avg       0.64      0.84      0.69      8773\n",
            "weighted avg       0.99      0.98      0.98      8773\n",
            "\n",
            "Wassenaar_2017\n",
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      0.05      0.09      7557\n",
            "           1       0.01      0.96      0.03       106\n",
            "\n",
            "    accuracy                           0.06      7663\n",
            "   macro avg       0.50      0.50      0.06      7663\n",
            "weighted avg       0.98      0.06      0.09      7663\n",
            "\n",
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.73      0.84      7557\n",
            "           1       0.04      0.86      0.08       101\n",
            "\n",
            "    accuracy                           0.73      7658\n",
            "   macro avg       0.52      0.80      0.46      7658\n",
            "weighted avg       0.98      0.73      0.83      7658\n",
            "\n",
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.73      0.84      7557\n",
            "           1       0.04      0.94      0.08        96\n",
            "\n",
            "    accuracy                           0.73      7653\n",
            "   macro avg       0.52      0.83      0.46      7653\n",
            "weighted avg       0.99      0.73      0.83      7653\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.68      0.81      7557\n",
            "           1       0.04      0.97      0.07        91\n",
            "\n",
            "    accuracy                           0.69      7648\n",
            "   macro avg       0.52      0.83      0.44      7648\n",
            "weighted avg       0.99      0.69      0.80      7648\n",
            "\n",
            "\n",
            "\n",
            "Local Outlier Factor\n",
            "Nelson_2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (5). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.94      0.41      0.57       286\n",
            "           1       0.29      0.91      0.43        75\n",
            "\n",
            "    accuracy                           0.51       361\n",
            "   macro avg       0.61      0.66      0.50       361\n",
            "weighted avg       0.81      0.51      0.54       361\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (10). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.92      0.45      0.61       286\n",
            "           1       0.27      0.84      0.41        70\n",
            "\n",
            "    accuracy                           0.53       356\n",
            "   macro avg       0.60      0.65      0.51       356\n",
            "weighted avg       0.79      0.53      0.57       356\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (15). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.46      0.62       286\n",
            "           1       0.28      0.92      0.43        65\n",
            "\n",
            "    accuracy                           0.54       351\n",
            "   macro avg       0.62      0.69      0.52       351\n",
            "weighted avg       0.84      0.54      0.59       351\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      0.37      0.54       286\n",
            "           1       0.25      0.98      0.40        60\n",
            "\n",
            "    accuracy                           0.48       346\n",
            "   macro avg       0.62      0.68      0.47       346\n",
            "weighted avg       0.86      0.48      0.52       346\n",
            "\n",
            "Muthu_2021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (5). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.97      0.45      0.61      2383\n",
            "           1       0.18      0.89      0.30       331\n",
            "\n",
            "    accuracy                           0.50      2714\n",
            "   macro avg       0.57      0.67      0.46      2714\n",
            "weighted avg       0.87      0.50      0.57      2714\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (10). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.47      0.63      2383\n",
            "           1       0.18      0.87      0.31       326\n",
            "\n",
            "    accuracy                           0.52      2709\n",
            "   macro avg       0.57      0.67      0.47      2709\n",
            "weighted avg       0.87      0.52      0.59      2709\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (15). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.14      0.25      2383\n",
            "           1       0.14      1.00      0.24       321\n",
            "\n",
            "    accuracy                           0.24      2704\n",
            "   macro avg       0.57      0.57      0.24      2704\n",
            "weighted avg       0.89      0.24      0.24      2704\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.98      0.45      0.62      2383\n",
            "           1       0.18      0.92      0.31       316\n",
            "\n",
            "    accuracy                           0.51      2699\n",
            "   macro avg       0.58      0.69      0.46      2699\n",
            "weighted avg       0.89      0.51      0.58      2699\n",
            "\n",
            "Hall_2012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (5). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.99      1.00      8689\n",
            "           1       0.57      0.60      0.58        99\n",
            "\n",
            "    accuracy                           0.99      8788\n",
            "   macro avg       0.78      0.80      0.79      8788\n",
            "weighted avg       0.99      0.99      0.99      8788\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (10). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.99      1.00      8689\n",
            "           1       0.53      0.72      0.61        94\n",
            "\n",
            "    accuracy                           0.99      8783\n",
            "   macro avg       0.76      0.86      0.80      8783\n",
            "weighted avg       0.99      0.99      0.99      8783\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (15). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.99      0.99      8689\n",
            "           1       0.41      0.87      0.56        89\n",
            "\n",
            "    accuracy                           0.99      8778\n",
            "   macro avg       0.71      0.93      0.78      8778\n",
            "weighted avg       0.99      0.99      0.99      8778\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.98      0.99      8689\n",
            "           1       0.34      0.89      0.50        84\n",
            "\n",
            "    accuracy                           0.98      8773\n",
            "   macro avg       0.67      0.94      0.74      8773\n",
            "weighted avg       0.99      0.98      0.99      8773\n",
            "\n",
            "Wassenaar_2017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (5). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 5 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.83      0.90      7557\n",
            "           1       0.07      0.89      0.12       106\n",
            "\n",
            "    accuracy                           0.83      7663\n",
            "   macro avg       0.53      0.86      0.51      7663\n",
            "weighted avg       0.99      0.83      0.89      7663\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (10). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 10 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.83      0.91      7557\n",
            "           1       0.06      0.79      0.11       101\n",
            "\n",
            "    accuracy                           0.83      7658\n",
            "   macro avg       0.53      0.81      0.51      7658\n",
            "weighted avg       0.98      0.83      0.89      7658\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (15). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento com 15 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.80      0.89      7557\n",
            "           1       0.05      0.88      0.10        96\n",
            "\n",
            "    accuracy                           0.80      7653\n",
            "   macro avg       0.53      0.84      0.49      7653\n",
            "weighted avg       0.99      0.80      0.88      7653\n",
            "\n",
            "Treinamento com 20 amostras:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.67      0.80      7557\n",
            "           1       0.03      0.96      0.06        91\n",
            "\n",
            "    accuracy                           0.67      7648\n",
            "   macro avg       0.52      0.81      0.43      7648\n",
            "weighted avg       0.99      0.67      0.79      7648\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer('all-distilroberta-v1')\n",
        "for clf_name in occ_classifiers:\n",
        "    print('\\n\\n' + clf_name)\n",
        "    for dataset in datasets:\n",
        "        print(dataset)\n",
        "        X, y = cria_dataset(dataset)\n",
        "\n",
        "        y[y==0] = -1\n",
        "\n",
        "        if not os.path.exists(os.path.join('/content/drive/MyDrive/occ/', clf_name)):\n",
        "            os.makedirs(os.path.join('/content/drive/MyDrive/occ/', clf_name))\n",
        "        folder = os.path.join('/content/drive/MyDrive/occ/', clf_name)\n",
        "\n",
        "        '''\n",
        "        Primeiramente foi feito variando k de 1 a 10. Porém, o f1 score ficava maior\n",
        "        que zero somente após k > 5, e variando muito pouco a cada iteração.\n",
        "        Com isso, foi feito com k começando em 5 e variando de 5 em 5 até 20 amostras.\n",
        "        '''\n",
        "        for k in range(5, 21, 5):\n",
        "            if clf_name == 'OneClassSVM':\n",
        "                clf = OneClassSVM(gamma='scale', nu=0.1)\n",
        "            elif clf_name == 'Isolation Forest':\n",
        "                clf = IsolationForest(contamination=0.1)\n",
        "            elif clf_name == 'Local Outlier Factor':\n",
        "                clf = LocalOutlierFactor(contamination=0.1, novelty=True)\n",
        "\n",
        "            labels_1_idx = [i for i, _ in enumerate(y) if y[i] == 1]\n",
        "            example_ids = np.random.choice(labels_1_idx, k, replace=False)\n",
        "            y_other = [l for i, l in enumerate(y) if i not in example_ids]\n",
        "            X_train = model.encode(X[example_ids])\n",
        "            X_test = model.encode([x for i, x in enumerate(X) if i not in example_ids])\n",
        "\n",
        "            clf.fit(X_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "\n",
        "            print(f'Treinamento com {k} amostras:')\n",
        "            cr = classification_report(y_other, y_pred, labels=[-1, 1] , zero_division=0)\n",
        "            print(cr)\n",
        "\n",
        "            with open(f'{folder}/{clf_name} - {dataset}.txt', 'a') as f:\n",
        "                f.write(f'\\n\\nTreinamento com {k} amostras\\n{cr}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODmIgkdWlPno",
        "outputId": "21de0dcb-f5b8-4e18-c215-d0e4d53550dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 10, 15, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2sj72YSH2MPH"
      },
      "outputs": [],
      "source": [
        "# for model_encoding in model_checkpoints:\n",
        "#     print('\\n\\n' + model_encoding)\n",
        "#     for model_name in occ_models:\n",
        "#         print('\\n\\n' + model_name)\n",
        "#         for dataset in datasets:\n",
        "#             folder_model = model_encoding.split(\"/\")[-1]\n",
        "#             print(dataset)\n",
        "\n",
        "#             X, y = cria_dataset(dataset)\n",
        "\n",
        "#             nu = len(y[y==1]) / len(y)\n",
        "\n",
        "#             if model_name == 'OneClassSVM':\n",
        "#                 model = OneClassSVM(gamma='scale', nu=nu)\n",
        "#             elif model_name == 'Isolation Forest':\n",
        "#                 model = IsolationForest(contamination=nu)\n",
        "#             elif model_name == 'Local Outlier Factor':\n",
        "#                 model = LocalOutlierFactor(contamination=nu, novelty=True)\n",
        "\n",
        "#             enc = SentenceTransformer(model_encoding)\n",
        "\n",
        "#             X = enc.encode(X)\n",
        "\n",
        "#             X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "#             y_test[y_test==1] = -1\n",
        "#             y_test[y_test==0] = 1\n",
        "\n",
        "#             model.fit(X_train[y_train==1])\n",
        "\n",
        "#             y_pred = model.predict(X_test)\n",
        "#             print(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1] , zero_division=0))\n",
        "\n",
        "#             if not os.path.exists(os.path.join('/content/drive/MyDrive/occ/sentence_transformers', folder_model)):\n",
        "#                 os.makedirs(os.path.join('/content/drive/MyDrive/occ/sentence_transformers', folder_model))\n",
        "#             if not os.path.exists(os.path.join('/content/drive/MyDrive/occ/sentence_transformers', folder_model, model_name)):\n",
        "#                 os.makedirs(os.path.join('/content/drive/MyDrive/occ/sentence_transformers', folder_model, model_name))\n",
        "#             folder = os.path.join('/content/drive/MyDrive/occ/sentence_transformers', folder_model, model_name)\n",
        "\n",
        "#             df = pd.DataFrame(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1] , zero_division=0, output_dict=True)).transpose()\n",
        "#             df.to_csv(f'{folder}/{dataset}.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVhww1qwQ2z0"
      },
      "source": [
        "###Feature extraction usando TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw-Ynyr1yjYs"
      },
      "outputs": [],
      "source": [
        "# # X, y = cria_dataset('Brouwer_2019')\n",
        "# X, y = cria_dataset('Leenaars_2020')\n",
        "\n",
        "# nu = len(y[y==1]) / len(y)\n",
        "# print(f'Percentual da classe positiva: {nu}')\n",
        "\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.3, random_state=42, stratify=y)\n",
        "# y_test[y_test==1] = -1\n",
        "# y_test[y_test==0] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhjfxCImQ_Ik"
      },
      "source": [
        "###Feature extraction usando sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GDxHvVUdmem"
      },
      "outputs": [],
      "source": [
        "# # X, y = cria_dataset('Moran_2021')\n",
        "# X, y = cria_dataset('Brouwer_2019')\n",
        "\n",
        "# nu = len(y[y==1]) / len(y)\n",
        "# print(f'Percentual da classe positiva: {nu}')\n",
        "\n",
        "# model = SentenceTransformer('google-bert/bert-base-uncased')\n",
        "\n",
        "# X = model.encode(X)\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# y_test[y_test==1] = -1\n",
        "# y_test[y_test==0] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFpWoCNLQkFO"
      },
      "source": [
        "###OneClassSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMqgnpTlu4hf"
      },
      "outputs": [],
      "source": [
        "# model_ocsvm = OneClassSVM(gamma='scale', nu=nu)\n",
        "\n",
        "# model_ocsvm.fit(X_train[y_train==1])\n",
        "\n",
        "# y_pred = model_ocsvm.predict(X_test)\n",
        "\n",
        "# print('F1 Score: %.3f' % f1_score(y_test, y_pred, pos_label=1))\n",
        "# print(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHb3iHYBQoA5"
      },
      "source": [
        "###Isolation Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJPEbMRDvID-"
      },
      "outputs": [],
      "source": [
        "# model_ocif = IsolationForest(contamination=nu)\n",
        "\n",
        "# model_ocif.fit(X_train[y_train==1])\n",
        "\n",
        "# y_pred = model_ocif.predict(X_test)\n",
        "\n",
        "# print('F1 Score: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, pos_label=1))\n",
        "# print(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWi_e9NvQsrK"
      },
      "source": [
        "###Local outlier factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNCI6s8TvJ8k"
      },
      "outputs": [],
      "source": [
        "# model_oclof = LocalOutlierFactor(contamination=nu, novelty=True)\n",
        "\n",
        "# model_oclof.fit(X_train[y_train==1])\n",
        "\n",
        "# y_pred = model_oclof.predict(X_test)\n",
        "\n",
        "# print('F1 Score: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, pos_label=1))\n",
        "# print(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNiRGNlpQvtD"
      },
      "source": [
        "###Eliptic envelope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHVD29vNvRlC"
      },
      "outputs": [],
      "source": [
        "# model_ocee = EllipticEnvelope(contamination=nu)\n",
        "\n",
        "# model_ocee.fit(X_train[y_train==1].toarray())\n",
        "\n",
        "# y_pred = model_ocee.predict(X_test)\n",
        "\n",
        "# print('F1 Score: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, pos_label=1))\n",
        "# print(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}