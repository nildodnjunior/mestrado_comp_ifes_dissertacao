{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from synergy_dataset import Dataset, iter_datasets\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dataset(dataset):\n",
    "    ds = Dataset(dataset)\n",
    "    ds = ds.to_frame()\n",
    "    ds = ds.fillna('')\n",
    "    title = ds['title']\n",
    "    abstract = ds['abstract']\n",
    "    X = np.array([x[0] + ' ' + x[1] for x in zip(title, abstract)])\n",
    "    y = np.array(ds['label_included'])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_models = ['OneClassSVM',\n",
    "              'Isolation Forest',\n",
    "              'Local Outlier Factor']\n",
    "\n",
    "model_checkpoints = ['sentence-transformers/all-MiniLM-L6-v2', \n",
    "                     'all-distilroberta-v1', \n",
    "                     'sentence-transformers/allenai-specter']\n",
    "\n",
    "datasets = ['Nelson_2002', 'Donners_2021', 'Oud_2018', 'van_der_Valk_2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento com 10 amostras:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.98      0.99      8689\n",
      "           1       0.25      0.74      0.37        94\n",
      "\n",
      "    accuracy                           0.97      8783\n",
      "   macro avg       0.62      0.86      0.68      8783\n",
      "weighted avg       0.99      0.97      0.98      8783\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Replacement index 1 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_other, y_pred, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m] , zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     21\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreport.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mClassification Report\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mConfusion Matrix\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mIndexError\u001b[0m: Replacement index 1 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "X, y = cria_dataset('Hall_2012')\n",
    "nu = len(y[y==1]) / len(y)\n",
    "model = SentenceTransformer('sentence-transformers/allenai-specter')\n",
    "\n",
    "y[y==0] = -1\n",
    "k = 10\n",
    "\n",
    "clf = IsolationForest(contamination=0.1, random_state=42)\n",
    "labels_1_idx = [i for i, _ in enumerate(y) if y[i] == 1]\n",
    "example_ids = np.random.choice(labels_1_idx, k, replace=False)\n",
    "y_other = [l for i, l in enumerate(y) if i not in example_ids]\n",
    "X_train = model.encode(X[example_ids])\n",
    "X_test = model.encode([x for i, x in enumerate(X) if i not in example_ids])\n",
    "clf.fit(X_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f'Treinamento com {k} amostras:')\n",
    "print(classification_report(y_other, y_pred, labels=[-1, 1] , zero_division=0))\n",
    "\n",
    "f = open('report.txt', 'w')\n",
    "f.write('Title\\n\\nClassification Report\\n\\n{}\\n'.format(test))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.33      0.25      0.29         5\n",
      "weighted avg       0.53      0.40      0.46         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y1 = [1, 1, 1, 0, 1]\n",
    "y2 = [1, 0, 1, 1, 0]\n",
    "test = classification_report(y1, y2, zero_division=0) \n",
    "print(test)\n",
    "f = open('report.txt', 'a')\n",
    "f.write(f'Treinamento com {10} amostras\\n{test}\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento com 1 amostras:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        79\n",
      "           1       0.78      1.00      0.88       286\n",
      "\n",
      "    accuracy                           0.78       365\n",
      "   macro avg       0.39      0.50      0.44       365\n",
      "weighted avg       0.61      0.78      0.69       365\n",
      "\n",
      "Treinamento com 2 amostras:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        78\n",
      "           1       0.79      1.00      0.88       286\n",
      "\n",
      "    accuracy                           0.79       364\n",
      "   macro avg       0.39      0.50      0.44       364\n",
      "weighted avg       0.62      0.79      0.69       364\n",
      "\n",
      "Treinamento com 3 amostras:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.18      0.73      0.29        77\n",
      "           1       0.58      0.10      0.17       286\n",
      "\n",
      "    accuracy                           0.23       363\n",
      "   macro avg       0.38      0.41      0.23       363\n",
      "weighted avg       0.49      0.23      0.20       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = cria_dataset('Hall_2012')\n",
    "nu = len(y[y==1]) / len(y)\n",
    "model = SentenceTransformer('sentence-transformers/allenai-specter')\n",
    "y[y==1] = -1\n",
    "y[y==0] = 1\n",
    "\n",
    "for k in range (1, 4):\n",
    "    clf = IsolationForest(contamination=nu)\n",
    "    labels_1_idx = [i for i, _ in enumerate(y) if y[i] == -1]\n",
    "    example_ids = np.random.choice(labels_1_idx, k, replace=False)\n",
    "    y_other = [l for i, l in enumerate(y) if i not in example_ids]\n",
    "    X_train = model.encode(X[example_ids])\n",
    "    X_test = model.encode([x for i, x in enumerate(X) if i not in example_ids])\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f'Treinamento com {k} amostras:')\n",
    "    print(classification_report(y_other, y_pred, labels=[-1, 1] , zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name google-bert/bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X, y = cria_dataset('Moran_2021')\n",
    "\n",
    "nu = len(y[y==1]) / len(y)\n",
    "print(f'Percentual da classe positiva: {nu}')\n",
    "\n",
    "model = SentenceTransformer('google-bert/bert-base-uncased')\n",
    "\n",
    "X = model.encode(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_test[y_test==1] = -1\n",
    "y_test[y_test==0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        20\n",
      "           1       1.00      0.95      0.97     10624\n",
      "\n",
      "    accuracy                           0.95     10644\n",
      "   macro avg       0.50      0.48      0.49     10644\n",
      "weighted avg       1.00      0.95      0.97     10644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_ocsvm = OneClassSVM(gamma='scale', nu=nu)\n",
    "\n",
    "model_ocsvm.fit(X_train[y_train==0])\n",
    "\n",
    "y_pred = model_ocsvm.predict(X_test)\n",
    "\n",
    "print(f1_score(y_true=y_test, y_pred=y_pred, pos_label=-1))\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X should be in csr_matrix format, got <class 'scipy.sparse._csc.csc_matrix'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ocif \u001b[38;5;241m=\u001b[39m IsolationForest(contamination\u001b[38;5;241m=\u001b[39mnu)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel_ocif\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_ocif\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(f1_score(y_true\u001b[38;5;241m=\u001b[39my_test, y_pred\u001b[38;5;241m=\u001b[39my_pred, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/ensemble/_iforest.py:349\u001b[0m, in \u001b[0;36mIsolationForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# Else, define offset_ wrt contamination parameter\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# To avoid performing input validation a second time we call\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# _score_samples rather than score_samples\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m100.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontamination)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/ensemble/_iforest.py:447\u001b[0m, in \u001b[0;36mIsolationForest._score_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    444\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# Take the opposite of the scores as bigger is better (here less abnormal)\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_chunked_score_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/ensemble/_iforest.py:477\u001b[0m, in \u001b[0;36mIsolationForest._compute_chunked_score_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    473\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_samples, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sl \u001b[38;5;129;01min\u001b[39;00m slices:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# compute score on the slices of test samples:\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m     scores[sl] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_score_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43msl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsample_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/ensemble/_iforest.py:504\u001b[0m, in \u001b[0;36mIsolationForest._compute_score_samples\u001b[0;34m(self, X, subsample_features)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree_idx, (tree, features) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_features_)\n\u001b[1;32m    501\u001b[0m ):\n\u001b[1;32m    502\u001b[0m     X_subset \u001b[38;5;241m=\u001b[39m X[:, features] \u001b[38;5;28;01mif\u001b[39;00m subsample_features \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 504\u001b[0m     leaves_index \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     depths \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decision_path_lengths[tree_idx][leaves_index]\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_average_path_length_per_tree[tree_idx][leaves_index]\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    510\u001b[0m     )\n\u001b[1;32m    511\u001b[0m denominator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m*\u001b[39m average_path_length_max_samples\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/tree/_classes.py:553\u001b[0m, in \u001b[0;36mBaseDecisionTree.apply\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    551\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    552\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32msklearn/tree/_tree.pyx:841\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree.apply\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/tree/_tree.pyx:844\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree.apply\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/tree/_tree.pyx:897\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._apply_sparse_csr\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X should be in csr_matrix format, got <class 'scipy.sparse._csc.csc_matrix'>"
     ]
    }
   ],
   "source": [
    "model_ocif = IsolationForest(contamination=nu)\n",
    "\n",
    "model_ocif.fit(X_train[y_train==0])\n",
    "\n",
    "y_pred = model_ocif.predict(X_test)\n",
    "\n",
    "print(f1_score(y_true=y_test, y_pred=y_pred, pos_label=-1))\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_oclof = LocalOutlierFactor(contamination=nu)\n",
    "\n",
    "model_oclof.fit(X_train[y_train==0])\n",
    "\n",
    "y_pred = model_ocif.predict(X_test)\n",
    "\n",
    "print(f1_score(y_true=y_test, y_pred=y_pred, pos_label=-1))\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Eliptic Envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22729.003897737718944 > -22730.036180019546009). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22683.664681049809587 > -22685.774269949706650). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22678.286004639787279 > -22681.148683326322498). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22687.833845535162254 > -22688.967325926489139). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22701.025685757686006 > -22701.261125405162602). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22674.824040878738742 > -22675.751412725559931). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22692.175960844124347 > -22711.817367694187851). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22666.914697387670458 > -22668.637511108769104). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22680.017882838310470 > -22680.960947108789696). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22724.352701890311437 > -22730.628869826221489). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22736.002656988057424 > -22742.684077265450469). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22711.594508006008255 > -22724.776844225936657). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22738.894510352634825 > -22740.656941101569828). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22766.136245124947891 > -22767.550742509683914). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n",
      "/home/junior/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:186: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-22769.069139777424425 > -22770.350362304063310). You may want to try with a higher value of support_fraction (current value: 0.658).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ocee \u001b[38;5;241m=\u001b[39m EllipticEnvelope(contamination\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel_ocee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_ocee\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(f1_score(y_true\u001b[38;5;241m=\u001b[39my_test, y_pred\u001b[38;5;241m=\u001b[39my_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_elliptic_envelope.py:184\u001b[0m, in \u001b[0;36mEllipticEnvelope.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the EllipticEnvelope model.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_, \u001b[38;5;241m100.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontamination)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:751\u001b[0m, in \u001b[0;36mMinCovDet.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    747\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe covariance matrix associated to your dataset is not full rank\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m     )\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# compute and store raw estimates\u001b[39;00m\n\u001b[0;32m--> 751\u001b[0m raw_location, raw_covariance, raw_support, raw_dist \u001b[38;5;241m=\u001b[39m \u001b[43mfast_mcd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43msupport_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcov_computation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nonrobust_covariance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massume_centered:\n\u001b[1;32m    758\u001b[0m     raw_location \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_features)\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:517\u001b[0m, in \u001b[0;36mfast_mcd\u001b[0;34m(X, support_fraction, cov_computation_method, random_state)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# find the best couples (location, covariance) on the merged set\u001b[39;00m\n\u001b[1;32m    516\u001b[0m selection \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mpermutation(n_samples)[:n_samples_merged]\n\u001b[0;32m--> 517\u001b[0m locations_merged, covariances_merged, supports_merged, d \u001b[38;5;241m=\u001b[39m \u001b[43mselect_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselection\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh_merged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_best_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_best_covariances\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_best_merged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcov_computation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_computation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# 3. Finally get the overall best (locations, covariance) couple\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1500\u001b[39m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;66;03m# directly get the best couple (location, covariance)\u001b[39;00m\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:334\u001b[0m, in \u001b[0;36mselect_candidates\u001b[0;34m(X, n_support, n_trials, select, n_iter, verbose, cov_computation_method, random_state)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_trials):\n\u001b[1;32m    332\u001b[0m         initial_estimates \u001b[38;5;241m=\u001b[39m (estimates_list[\u001b[38;5;241m0\u001b[39m][j], estimates_list[\u001b[38;5;241m1\u001b[39m][j])\n\u001b[1;32m    333\u001b[0m         all_estimates\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 334\u001b[0m             \u001b[43m_c_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m                \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m                \u001b[49m\u001b[43mremaining_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m                \u001b[49m\u001b[43minitial_estimates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_estimates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcov_computation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_computation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m         )\n\u001b[1;32m    344\u001b[0m all_locs_sub, all_covs_sub, all_dets_sub, all_supports_sub, all_ds_sub \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;241m*\u001b[39mall_estimates\n\u001b[1;32m    346\u001b[0m )\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# find the `n_best` best results among the `n_trials` ones\u001b[39;00m\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:157\u001b[0m, in \u001b[0;36m_c_step\u001b[0;34m(X, n_support, random_state, remaining_iterations, initial_estimates, verbose, cov_computation_method)\u001b[0m\n\u001b[1;32m    155\u001b[0m previous_support \u001b[38;5;241m=\u001b[39m support\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# compute a new support from the full data set mahalanobis distances\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpinvh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcovariance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m X_centered \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m-\u001b[39m location\n\u001b[1;32m    159\u001b[0m dist \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mdot(X_centered, precision) \u001b[38;5;241m*\u001b[39m X_centered)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/scipy/linalg/_basic.py:1421\u001b[0m, in \u001b[0;36mpinvh\u001b[0;34m(a, atol, rtol, lower, return_rank, check_finite)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;124;03mCompute the (Moore-Penrose) pseudo-inverse of a Hermitian matrix.\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \n\u001b[1;32m   1419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m a \u001b[38;5;241m=\u001b[39m _asarray_validated(a, check_finite\u001b[38;5;241m=\u001b[39mcheck_finite)\n\u001b[0;32m-> 1421\u001b[0m s, u \u001b[38;5;241m=\u001b[39m \u001b[43m_decomp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m t \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m   1423\u001b[0m maxS \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(s))\n",
      "File \u001b[0;32m~/Mestrado Comp Ifes/Dissertação/occ/.venv/lib/python3.8/site-packages/scipy/linalg/_decomp.py:561\u001b[0m, in \u001b[0;36meigh\u001b[0;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver)\u001b[0m\n\u001b[1;32m    558\u001b[0m         lwork_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlwork\u001b[39m\u001b[38;5;124m'\u001b[39m: lw}\n\u001b[1;32m    560\u001b[0m     drv_args\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m: lower, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompute_v\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _job \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m--> 561\u001b[0m     w, v, \u001b[38;5;241m*\u001b[39mother_args, info \u001b[38;5;241m=\u001b[39m \u001b[43mdrv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdrv_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlwork_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Generalized problem\u001b[39;00m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;66;03m# 'gvd' doesn't have lwork query\u001b[39;00m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ocee = EllipticEnvelope(contamination=nu)\n",
    "\n",
    "model_ocee.fit(X_train[y_train==0])\n",
    "\n",
    "y_pred = model_ocee.predict(X_test)\n",
    "\n",
    "print(f1_score(y_true=y_test, y_pred=y_pred, pos_label=-1))\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, labels=[-1, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
